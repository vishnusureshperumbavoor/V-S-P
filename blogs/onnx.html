<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>VSP</title>
    <link
      href="//fonts.googleapis.com/css?family=Nunito:400,700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="assets/css/style-starter.css" />
  </head>

  <body>
    <header>
      <div class="w3l-header" id="home">
        <div class="container">
          <nav class="navbar navbar-expand-lg navbar-dark pl-0 pr-0">
            <a class="navbar-brand m-0" href="../index.html"
              ><span class="fa fa-gamepad"></span> VSP
            </a>
            <span class="navbar-toggler-icon fa fa-bars"></span>
            <div class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav ml-auto">
                <li class="nav-item mr-lg-4">
                  <a class="nav-link pl-0 pr-0" href="../index.html">Home</a>
                  <a class="nav-link pl-0 pr-0" href="../blogs.html">Blogs</a>
                </li>
              </ul>
            </div>
          </nav>
        </div>
      </div>
    </header>

    <section class="w3l-about-bottom py-5" id="about">
      <div class="container py-lg-5 py-md-3">
        <div class="row middle-grids">
          <div class="col-lg-12 advantage-grid-info">
            <div class="advantage_left">
              <h1 class="font-weight">ONNX</h1>
              This is my blog on how a technology which is introduced by Meta
              for the interoperability between the pytorch and Caffe models is
              now started to take over the planet. <br />
              <h2 class="mt-2">Initial days</h2>
              Meta introduced ONNX as a way for interoperability between their
              pytorch and Caffe models. Later on, it was adopted by other ML
              frameworks such as Tensorflow, MXNet, and more.
              <h2 class="mt-2">Next Stage</h2>
              Even though it is introduced for interoperability, it's course
              changed since Micorsoft introduced ONNX Runtime as a runtime
              environment for ONNX models. Since then ONNX models started used
              in mobiles, laptops, web browsers and embedded devices. <br />
              <h2 class="mt-2">Why ONNX is standing out from others</h2>
              1. Ability to use WebGPU which gives access to graphics APIs
              Vulkan (Linux & Android), DirectX (Windows) & Metal (iOS & Mac). <br />
              2. Ability to do on-device training <br />
              &nbsp;&nbsp;&nbsp;&nbsp;This feature helps to avoid losing
              sensitive data to the cloud/server. <br />
              3. Compatibility with billion parameter models such as phi4,
              whisper, llama, sam2, gemma, etc. <br />
              4. Support TensorRT (NVIDIA GPUs) & OpenVINO (Intel CPUs) <br />
              5. Has APIs for python, JavaScript, rust, cpp, c#, java, kotlin,
              swift etc. <br />
              6. Supports multi-threading (Using web workers in web browsers)<br />
              7. Supports graph level optimization and quantization <br />
              8. Major open source projects cornerstonejs and transformersjs is
              already implemented onnx on their platforms.
              <h2 class="mt-2">WebGPU vs WebGL</h2>
              Both are browser rendering tools. WebGPU is the successor of
              WebGL, enabling direct use of compute shaders for advanced
              graphics and parallel processing tasks.
              <h3 class="mt-2">What is WebGL</h3>
              <p class="mb-3 mt-2">
                WebGL is a JavaScript framework used to render 2D and 3D
                graphics in your browser. Released in 2011, it has become the
                backbone of almost all graphical rendering on the web. Most
                major web-based rendering frameworks, such as Three.js,
                Babylon.js, Box2D, and Cornerstone.js, are built on top of
                WebGL. Until the last few years, the phrase "rendering on the
                web" was synonymous with WebGL.
                <br />
              </p>
              <h3 class="mt-2">Drawbacks of WebGL</h3>
              <p class="mt-4">
                WebGL 2.0, which is powered by OpenGL ES 3.0, which was released in
                2008. This means that the capabilities of WebGL are rooted in a
                graphics API that is over 16 years old.
              </p>
              <p class="mt-4">
                There has been significant development in consumer-level GPUs,
                starting with the GeForce 200 Series released in 2008. Since
                then, the series has progressed through the 300, 400, ..., 900,
                10 series, 20 series, and now the 40 series. Alongside this,
                modern graphics APIs like DirectX 12, Vulkan, and Metal have
                emerged, enabling advanced capabilities in desktop and mobile
                gaming. However, browser-based games still rely on WebGL, which
                is based on OpenGL ES 3.0 (released in 2008). This means
                web-based rendering is significantly behind compared to desktop
                and mobile rendering. As a result, web browsers face performance
                and frame rate limitations, and many advanced features of modern
                GPUs remain inaccessible due to WebGL's reliance on outdated
                technology.
              </p>
              <h3 class="mt-2">What is WebGPU</h3>
              <p class="mb-3 mt-2">
                WebGPU is the successor of WebGL. It's development started in
                2017. It enabled us to use the latest graphics cards features.
                WebGPU is supported on Chrome, Edge, Firefox, Safari etc.
                <br />
                WebGPU supports multi-threading which is helpful while
                downloading the model without using main thread.
                <br />
                WebGPU is powered by graphics APIs such as DirectX 12, Vulkan
                and Metal based on the browser platform.
              </p>
              <h3 class="mt-2">WebGPU for Machine Learning</h3>
              <p class="mb-3 mt-2">
                ML frameworks such as Tensorflow.js and Transformers.js are
                using WebGPU under the hood. If you want to do any kind of
                computations on the tensorflow, tensorflow has to convert the
                input tensor into textual or vertex data and again back to
                tensor data. WebGPU supports Compute Shader. Compute Shaders are
                General Purpose Programs that you can run on the GPUs. When
                tensorflow is directly able to use the computer shaders there is
                no need to convert the input data into vertex or textures. You
                can directly perform the computation on the shaders. Because of
                the less overhead it enabled the developers to run
                encoder-decoder ML models such as SAM2, Whisper, llama, gemma on
                the client side.
              </p>
              <h3 class="mt-2">
                Advantages of using ML model on the client side
              </h3>
              <ul>
                <li>Gives privacy to the user data.</li>
                <li>
                  It enabled offline compute once the model is downloaded.
                </li>
                <li>
                  Since no cloud is involved the latency will be lower once the
                  model is downloaded.
                </li>
                <li>
                  Cost of running the model is zero since there are no OpenAI,
                  Anthropic or AWS API is involved.
                </li>
              </ul>
            </div>
            <h3 class="mt-2">Transformers js</h3>
            Transformers.js is a powerful library that allows developers to run
            ML models directly in the browser, leveraging the capabilities of
            modern web technologies. <br />
            Transformers.js is designed to be functionally equivalent to Hugging
            Face's Python Transformers library, enabling users to run the same
            pretrained models with a similar API. <br />
            This allows for seamless integration of advanced ML tasks without
            server-side processing.
            <h3 class="mt-2">
              @huggingface/transformers vs @xenova/transformers
            </h3>
            <h4>@huggingface/transformers</h4>
            Supports a wide range of pretrained models from the Hugging Face
            Model Hub <br />
            <h4>@xenova/transformers</h4>
            Developed by popular developer Xenova <br />
            Focuses on providing lightweight models optimized for in-browser
            execution.
            <h3 class="mt-2">Pre-trained models</h3>
            Pre-trained models are ML models that have been previously trained
            on large datasets and can be fine-tuned or directly used for various
            tasks. ex: llama, llava, phi3, sam2, deepseek etc.
            <h3 class="mt-2">Popular Transformers Pipelines</h3>
            <strong>text2text-generation</strong>: LaMini-Flan-T5-783M <br />
            <strong>translation</strong>: nllb-200-distilled-600M,
            Xenova/m2m100_418M, mbart-large-50-many-to-many-mmt<br />
            <strong>text-generation</strong> (for next word prediction):
            distilgpt2, codegen-350M-mono<br />
            <strong>automatic-speech-recognition</strong> (for speech to text):
            whisper-tiny.en, whisper-small <br />
            <strong>image-to-text</strong>: vit-gpt2-image-captioning,
            trocr-small-handwritten<br />
            <strong>image-segmentation</strong>: detr-resnet-50-panoptic <br />
            <strong>object-detection</strong>: detr-resnet-50<br />
            <strong>document-question-answering</strong> (RAG implementation):
            donut-base-finetuned-docvqa<br />
            <strong>text-to-speech</strong>: speecht5_tts, mms-tts-fra<br />
            <strong>image-to-image</strong>: swin2SR-classical-sr-x2-64 <br />
            <h3 class="mt-2">Popular Transformers js Models</h3>
            Whisper (OpenAI) <br />
            GPT2 (OpenAI)<br />
            Llava <br />
            Llama (Meta) <br />
            SAM (Meta)<br />
            Cohere <br />
            Gemma2 (Google)<br />
            Qwen2 <br />
            Phi3 (Micorsoft)<br />
            Mistral <br />
            Falcon <br />
            MusicGen <br />
            YolosObjectDetection <br />
            VisionEncoderDecoder <br />
          </div>
        </div>
      </div>
    </section>

    <footer>
      <section class="w3l-footers-1">
        <div class="footer py-3">
          <div class="container">
            <div class="footer-content">
              <div class="row">
                <div class="col-lg-8 footer-left">
                  <p class="m-0">
                    &copy; 2025 All Rights Reserved | Design by VSP
                  </p>
                </div>
                <div
                  class="col-lg-4 footer-right text-lg-right text-center mt-lg-0 mt-3"
                >
                  <ul class="social m-0 p-0">
                    <li>
                      <a href="https://github.com/vishnusureshperumbavoor"
                        >Github<span class="fa fa-github"></span
                      ></a>
                    </li>
                    <li>
                      <a
                        href="https://www.linkedin.com/in/vishnu-suresh-perumbavoor-9a7a8223a/"
                        >LinkedIn<span class="fa fa-linkedin"></span
                      ></a>
                    </li>
                    <li>
                      <a href="https://t.me/vishnusureshperumbavoor"
                        >Telegram<span class="fa fa-telegram"></span
                      ></a>
                    </li>
                    <li>
                      <a
                        href="https://www.instagram.com/vishnusureshperumbavoor/"
                        >Instagram<span class="fa fa-instagram"></span
                      ></a>
                    </li>
                    <li>
                      <a href="http://www.twitter.com/vspeeeeee"
                        >Twitter/X<span class="fa fa-twitter"></span
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>
    </footer>
  </body>
</html>
<style>
  body {
    background-color: #000;
    color: #7cfc00;
  }
  ul li a {
    color: #7df9ff;
  }
</style>
