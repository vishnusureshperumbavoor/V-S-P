<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <title>VSP</title>
    <link
      href="//fonts.googleapis.com/css?family=Nunito:400,700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="assets/css/style-starter.css" />
  </head>

  <body>
    <header>
      <div class="w3l-header" id="home">
        <div class="container">
          <nav class="navbar navbar-expand-lg navbar-dark pl-0 pr-0">
            <a class="navbar-brand m-0" href="../index.html"
              ><span class="fa fa-gamepad"></span> VSP
            </a>
            <span class="navbar-toggler-icon fa fa-bars"></span>
            <div class="collapse navbar-collapse" id="navbarNav">
              <ul class="navbar-nav ml-auto">
                <li class="nav-item mr-lg-4">
                  <a class="nav-link pl-0 pr-0" href="../index.html">Home</a>
                  <a class="nav-link pl-0 pr-0" href="../blogs.html">Blogs</a>
                </li>
              </ul>
            </div>
          </nav>
        </div>
      </div>
    </header>

    <section class="w3l-about-bottom py-5" id="about">
      <div class="container py-lg-5 py-md-3">
        <div class="row middle-grids">
          <div class="col-lg-12 advantage-grid-info">
            <div class="advantage_left">
              <h1 class="font-weight">AI on the client side</h1>
              This is my series related to the implementation of AI on the
              client side. I will be covering WebGPU, ONNX and Encoder-Decoder
              models, transformers.js, WebWorkers etc.
              <h2 class="mt-2">WebGPU vs WebGL</h2>
              Both are browser rendering tools. WebGPU is the successor of WebGL
              which enables us to use Compute Shaders directly.
              <h3 class="mt-2">What is WebGL</h3>
              <p class="mb-3 mt-2">
                WebGL is a javascript framework to render 2D and 3D graphics on
                your browser. Released in 2011. Almost all the graphics on the
                browsers are browsers are handled by WebGL. Most of the major
                web-based rendering frameworks such as three.js, babylon.js,
                box2D, cornerstone.js are written on top of WebGL. Until last
                few years "rendering on the web == WebGL".
                <br />
                WebGL is powered by Graphics API OpenGL.
              </p>
              <h3 class="mt-2">Drawbacks of WebGL</h3>
              <p class="mt-4">
                The latest version of WebGL which is WebGL 2.0 is powered by
                OpenGL ES 3.0. It is came out in 2008. So basically the
                capabilities of WebGL is from a graphics API which is released
                16+ years back.
              </p>
              <p class="mt-4">
                There has been significant development in consumer level GPUs,
                starting with the GeForce 200 Series released in 2008. Since
                then, the series has progressed through the 300, 400, ..., 900,
                10 series, 20 series, and now the 40 series. Now we have
                graphics APIs such as DirectX 12, Vulkan, Metal etc. So using
                these graphics cards and graphics APIs there have been a huge
                development in the desktop/mobile games. But the browser games
                are still using WebGL which is still using OpenGL 3.0. So you
                can now imagine how behind is the web based rendering if you
                compare that with mobile/desktop based rendering. We have
                performance and frame rate issues on the web browsers. As since
                WebGL is till used OpenGL3.0 there are many functionalities of
                the SOTA graphic cards which we are not able to use on browsers.
              </p>
              <h3 class="mt-2">What is WebGPU</h3>
              <p class="mb-3 mt-2">
                WebGPU is the successor of WebGL. It's development started in
                2017. It enabled us to use the latest graphics cards features.
                WebGPU is supported on Chrome, Edge, Firefox, Safari etc.
                <br />
                WebGPU supports multi-threading which is helpful while
                downloading the model without using main thread.
                <br />
                WebGPU is powered by graphics APIs such as DirectX 12, Vulkan
                and Metal based on the browser platform.
              </p>
              <h3 class="mt-2">WebGPU for Machine Learning</h3>
              <p class="mb-3 mt-2">
                ML frameworks such as Tensorflow.js and Transformers.js are
                using WebGPU under the hood. If you want to do any kind of
                computations on the tensorflow, tensorflow has to convert the
                input tensor into textual or vertex data and again back to
                tensor data. WebGPU supports Compute Shader. Compute Shaders are
                General Purpose Programs that you can run on the GPUs. When
                tensorflow is directly able to use the computer shaders there is
                no need to convert the input data into vertex or textures. You
                can directly perform the computation on the shaders. Because of
                the less overhead it enabled the developers to run
                encoder-decoder ML models such as SAM2, Whisper, llama, gemma on
                the client side.
              </p>
              <h3 class="mt-2">
                Advantages of using ML model on the client side
              </h3>
              <ul>
                <li>Gives privacy to the user data.</li>
                <li>
                  It enabled offline compute once the model is downloaded.
                </li>
                <li>
                  Since no cloud is involved the latency will be lower once the
                  model is downloaded.
                </li>
                <li>
                  Cost of running the model is zero since there are no OpenAI,
                  Anthropic or AWS API is involved.
                </li>
              </ul>
              <h3 class="mt-2">ONNX models</h3>
              The Open Neural Network eXchange (ONNX) is an open-source format
              designed to facilitate the representation and interoperability of
              ML models across different frameworks. <br />
              This standard enables developers to share models between popular
              ML libraries such as TensorFlow & PyTorch, without needing to
              retrain them for each specific framework.
              <h3 class="mt-2">Web Workers</h3>
              A Web Worker is a JavaScript script that runs independently of the
              main thread. <br />
              This means that while the worker is processing data, the main
              thread remains free to handle user interactions, such as clicks
              and scrolling, ensuring that the web application remains
              responsive. <br />
              Web Workers can handle downloading the ML models.
            </div>
            <h3 class="mt-2">Transformers js</h3>
            Transformers.js is a powerful library that allows developers to run
            ML models directly in the browser, leveraging the capabilities of
            modern web technologies. <br />
            Transformers.js is designed to be functionally equivalent to Hugging
            Face's Python Transformers library, enabling users to run the same
            pretrained models with a similar API. <br />
            This allows for seamless integration of advanced ML tasks without
            server-side processing.
            <h3 class="mt-2">
              @huggingface/transformers vs @xenova/transformers
            </h3>
            <h4>@huggingface/transformers</h4>
            Supports a wide range of pretrained models from the Hugging Face
            Model Hub <br />
            <h4>@xenova/transformers</h4>
            Developed by popular developer Xenova <br />
            Focuses on providing lightweight models optimized for in-browser
            execution.
            <h3 class="mt-2">Pre-trained models</h3>
            Pre-trained models are ML models that have been previously trained
            on large datasets and can be fine-tuned or directly used for various
            tasks. ex: llama, llava, phi3, sam2, deepseek etc.
            <h3 class="mt-2">Popular Transformers Pipelines</h3>
            <strong>text2text-generation</strong>: LaMini-Flan-T5-783M <br />
            <strong>translation</strong>: nllb-200-distilled-600M,
            Xenova/m2m100_418M, mbart-large-50-many-to-many-mmt<br />
            <strong>text-generation</strong> (for next word prediction):
            distilgpt2, codegen-350M-mono<br />
            <strong>automatic-speech-recognition</strong> (for speech to text):
            whisper-tiny.en, whisper-small <br />
            <strong>image-to-text</strong>: vit-gpt2-image-captioning,
            trocr-small-handwritten<br />
            <strong>image-segmentation</strong>: detr-resnet-50-panoptic <br />
            <strong>object-detection</strong>: detr-resnet-50<br />
            <strong>document-question-answering</strong> (RAG implementation):
            donut-base-finetuned-docvqa<br />
            <strong>text-to-speech</strong>: speecht5_tts, mms-tts-fra<br />
            <strong>image-to-image</strong>: swin2SR-classical-sr-x2-64 <br />
            <h3 class="mt-2">Popular Transformers js Models</h3>
            Whisper (OpenAI) <br />
            GPT2 (OpenAI)<br />
            Llava <br />
            Llama (Meta) <br />
            SAM (Meta)<br />
            Cohere <br />
            Gemma2 (Google)<br />
            Qwen2 <br />
            Phi3 (Micorsoft)<br />
            Mistral <br />
            Falcon <br />
            MusicGen <br />
            YolosObjectDetection <br />
            VisionEncoderDecoder <br />
          </div>
        </div>
      </div>
    </section>

    <footer>
      <section class="w3l-footers-1">
        <div class="footer py-3">
          <div class="container">
            <div class="footer-content">
              <div class="row">
                <div class="col-lg-8 footer-left">
                  <p class="m-0">
                    &copy; 2025 All Rights Reserved | Design by VSP
                  </p>
                </div>
                <div
                  class="col-lg-4 footer-right text-lg-right text-center mt-lg-0 mt-3"
                >
                  <ul class="social m-0 p-0">
                    <li>
                      <a href="https://github.com/vishnusureshperumbavoor"
                        >Github<span class="fa fa-github"></span
                      ></a>
                    </li>
                    <li>
                      <a
                        href="https://www.linkedin.com/in/vishnu-suresh-perumbavoor-9a7a8223a/"
                        >LinkedIn<span class="fa fa-linkedin"></span
                      ></a>
                    </li>
                    <li>
                      <a href="https://t.me/vishnusureshperumbavoor"
                        >Telegram<span class="fa fa-telegram"></span
                      ></a>
                    </li>
                    <li>
                      <a
                        href="https://www.instagram.com/vishnusureshperumbavoor/"
                        >Instagram<span class="fa fa-instagram"></span
                      ></a>
                    </li>
                    <li>
                      <a href="http://www.twitter.com/vspeeeeee"
                        >Twitter/X<span class="fa fa-twitter"></span
                      ></a>
                    </li>
                  </ul>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>
    </footer>
  </body>
</html>
<style>
  body {
    background-color: #000;
    color: #7cfc00;
  }
  ul li a {
    color: #7df9ff;
  }
</style>
